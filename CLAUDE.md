# CLAUDE.md

## Project overview

SEW (Software Engineering Workbench) is a domain modeling platform that combines compiler techniques, IDE integration, 
and visual modeling for complex software design.
It provides custom DSLs for software engineering artifacts (domains, use cases, aggregates, events, etc.) with IntelliJ
IDEA plugin support.

## Build commands

### Building the project

```bash
./gradlew build
```

### Running tests

```bash
# Run all tests
./gradlew test

# Run tests for specific module
./gradlew :km:test

# Run specific test class
./gradlew :swe:test --tests "org.setms.swe.e2e.EndToEndTest"

# Run all checks, including tests
./gradlew check
```


## Project structure

The project is a multi-module Gradle build with the following modules:

### km (Knowledge Management)

The foundational core module providing:
- **Artifact Model**: Base `Artifact` class from which all domain entities inherit
- **Workspace Management**: Resource abstraction (`Workspace`, `Resource`, `DirectoryWorkspace`)
- **Validation Framework**: `Diagnostic` system with `Location` tracking and severity levels
- **Tool Framework**: Base classes for `ArtifactTool<T>` and `StandaloneTool` implementations
- **Diagram Rendering**: JGraphX-based visualization

### swe (Software Engineering)

Domain-specific models and tools organized under `org.setms.swe.domain.model.sdlc`:

- **stakeholders**: `User`, `Owner`, `Person`
- **domainstory**: `DomainStory` for narrative requirements
- **usecase**: `UseCase`, `Scenario` for behavior specifications
- **design**: `Entity`, `Field`, `Command`, `Aggregate`, `ReadModel`
- **ddd**: `Domain`, `Subdomain`, `EventStorm`, `Term`, `Sequence`
- **architecture**: `Decision` for architectural decisions
- **acceptance**: Acceptance testing support
- **code**: Programming language models

Domain Services in `org.setms.swe.domain.services`.

### intellij-lang-sal

IntelliJ language support for SAL (Structured Artifact Language).

### intellij-lang-acceptance

IntelliJ language support for Acceptance test format.

### intellij

Full IntelliJ IDEA plugin that integrates all components:
- **File Type System**: 20+ custom file types (`.entity`, `.command`, etc.)
- **Editor Providers**: Visual editors for domains, domain stories, etc
- **Language Support**: Syntax highlighting, completion, and annotations
- **IDE Integration**: `IntellijWorkspace` bridges `VirtualFile` system to workspace resources
- **Validation**: Background validation with `KmStartupActivity` and `FileListener`
- **UI**: Task window for displaying diagnostics and suggestions

### Softure

Future Spring Boot web application providing web UI for SEW.

## High-level architecture

### Artifact system

All domain entities inherit from `Artifact`:
- `FullyQualifiedName` - Package + name identification (e.g., `org.example.UserAggregate`)
- Validation with location-based diagnostics
- Links to other artifacts via references

### Tool pattern

The system uses a plugin-based Tool architecture:
- Tools declare inputs via `Inputs` class (what artifacts they depend on)
- Tools discovered via ServiceLoader/reflection
- Outputs include diagnostics (`.km/diagnostics/`) and reports (`.km/reports/`)

### Workspace & file watching

- `Workspace` abstracts file system access
- `DirectoryWorkspace` monitors project directory for changes
- `.km/inputs/` caches resolved artifact dependencies per tool

### Data flow
```
User Files (.entity, .command, etc.)
        ↓
Workspace (monitors changes)
        ↓
ProcessOrchestrator (main orchestrator)
        ├→ Parse via Format.newParser()
        └→ Trigger Tools
        ↓
Tool Pipeline:
     ├→ Resolve inputs (gather dependencies)
     ├→ Validate (produce diagnostics)
     └→ Generate reports
        ↓
Output:
  ├→ Diagnostics JSON (.km/diagnostics/)
  └→ Reports (.km/reports/)
```

See [Custom DSLs and file formats](docs/format.md)

## Testing approach

### Acceptance test-driven development

The preferred workflow in outside in:

1. Add an expectation that makes `EndToEndTest` fail.
2. Then add a unit test that localizes (part of) that failure.
3. Then update/add code to fix the failing unit test.
4. Repeat with step 2 until `EndToEndTest` passes.

- CRITICAL: **Never** write or change production code without a failing test that demands the change
- CRITICAL: **Always** let the user review the unit test before proceeding with the implementation.

Sometimes the user will start the workflow at step 2 (regular TDD).

### How the end-to-end test works

`EndToEndTest` (`swe/src/test/java/org/setms/swe/e2e/EndToEndTest.java`) simulates a human
software engineer working through an iterative design process. It uses resources in
`swe/src/test/resources/e2e/`, organized as numbered iteration directories (`01/`, `02/`, etc),
each containing an `iteration.yaml` that defines:

- **outputs** - Expected file paths that should exist in the workspace at the start of the iteration,
  generated by applying suggestions in the previous iteration.
- **inputs** - Artifact files (with `file` and `location`) to copy into the workspace, simulating
  human-created artifacts.
- **diagnostics** - Expected diagnostic messages that SEW should produce after processing the inputs.

Each iteration runs three steps in order:

1. **Verify outputs** - Check that files generated by the previous iteration's suggestions match the
   expected content in `NN/outputs/`. Comparison is by exact content.
2. **Copy inputs** - Copy input files from `NN/inputs/` into the workspace at their specified
   locations, triggering the `ProcessOrchestrator` to parse and validate.
3. **Assert diagnostics** - Wait (up to 5 seconds) for exactly the expected diagnostics to appear.
   Every diagnostic must have suggestions. Apply all suggestions and verify no new diagnostics
   result. Files created or changed by suggestions become the outputs verified in the next iteration.


### Test frameworks

- JUnit 5 (JUnit Platform)
- Property-based testing with JQwik
- Mockito for test mocking

## Development notes

### Technology decisions (topics & resolver)

Technology choices are modeled as `Decision` artifacts (`.decision` files) with a topic and a choice.
Topics are declared by `TopicProvider` implementations, discovered via ServiceLoader
(`META-INF/services/org.setms.swe.domain.model.sdlc.architecture.TopicProvider`).

Key classes:
- **`TopicProvider`** — declares `topics()`, `dependsOn()`, and `isValidChoice(topic, choice)`.
  A provider can declare a topic without validating choices (validation may live in another provider).
- **`Topics`** — static registry loaded via ServiceLoader. Provides `names()` and `isValidChoice()`.
- **`TechnologyResolverImpl`** — reads `Decision` artifacts, groups them by topic, and chains
  requirements: each missing decision emits a diagnostic with a suggestion that creates a template
  `.decision` file. Once all decisions are present, it creates the appropriate generator
  (e.g., `JavaUnitGenerator`).

To add a new technology decision:
1. Create a `TopicProvider` in `swe/.../sdlc/code/` declaring the topic and its `dependsOn()`.
2. Add choice validation in the language-specific provider (e.g., `JavaLanguage.isValidChoice()`) if the choice depends
  on the programming language.
3. Register in `META-INF/services/org.setms.swe.domain.model.sdlc.architecture.TopicProvider`.
4. In `TechnologyResolverImpl`: extract the new topic from `groupByTopic()`, add a missing-decision
   diagnostic with suggestion code, and handle `applySuggestion()` via `pickDecision()`.
5. Update e2e iterations: insert a new iteration between the prerequisite decision and the
   generation step (the new iteration provides the decision as input and expects the next diagnostic).

### Code style

- Code formatting enforced via Spotless plugin
- Lombok used for reducing boilerplate — use `@RequiredArgsConstructor` instead of hand-written
  constructors that only assign `final` fields
- Java 25 language features available
- Run `./gradlew spotlessApply` before committing
- Comments MUST explain **why**, NOT **what**
- Don't discuss implementation details in JavaDoc - that's for documenting the API
- Use the `var` keyword where possible, but if that requires a type cast
  - Good: `var name = "John";` Bad: `String name = "John";`
  - Good: `var list = new ArrayList<String>();` Bad: `List<String> list = new ArrayList<>();`
  - Good: `String name = null;` Bad: `var name = (String) null;`
- Helper methods directly follow the method that first calls them
- If a data object has chained setters, use chaining
- If a variable is used in a `return`, it must be called `result`
- If a variable is used in assertions or verifications, it must be called `actual`
- Test methods must follow the Arrange/Act/Assert pattern
  - These sections MUST be separated by a blank line
  - No other blank lines are allowed
  - No section may be more than 10 lines, extract helper methods is necessary
- CRITICAL: Always re-use as much as possible, both in production and in test code
